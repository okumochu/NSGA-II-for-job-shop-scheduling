{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSGA-II for Job Shop Scheduling Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NSGA-II](NSGA-II%20proccess.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q numpy \n",
    "%pip install -q pandas\n",
    "%pip install -q matplotlib\n",
    "%pip install -q plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_time\n",
      "   Job  O1  O2  O3  O4  O5  O6  O7  O8  O9  O10\n",
      "0  J1  29  78   9  36  49  11  62  56  44   21\n",
      "1  J2  43  90  75  11  69  28  46  46  72   30\n",
      "2  J3  91  85  39  74  90  10  12  89  45   33\n",
      "3  J4  81  95  71  99   9  52  85  98  22   43\n",
      "4  J5  14   6  22  61  26  69  21  49  72   53 \n",
      "\n",
      "machine_seq\n",
      "   Job  O1  O2  O3  O4  O5  O6  O7  O8  O9  O10\n",
      "0  J1   1   2   3   4   5   6   7   8   9   10\n",
      "1  J2   1   3   5  10   4   2   7   6   8    9\n",
      "2  J3   2   1   4   3   9   6   8   7  10    5\n",
      "3  J4   2   3   1   5   7   9   8   4  10    6\n",
      "4  J5   3   1   2   6   4   5   9   8  10    7 \n",
      "\n",
      "Priority & Due Date\n",
      "   Job  Priority  Due date\n",
      "0  J1        10       919\n",
      "1  J2         5       785\n",
      "2  J3         1       907\n",
      "3  J4         5       849\n",
      "4  J5        10       887 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameter Definition\n",
    "num_jobs = 10\n",
    "num_machines = 10\n",
    "\n",
    "pop_size = 10\n",
    "mutation_rate = 0.4\n",
    "crossover_rate = 0.5\n",
    "max_iteration_time = 10\n",
    "num_elitism_survivors = pop_size\n",
    "\n",
    "processing_time = pd.read_csv(\"Processing Time.csv\")\n",
    "machine_sequence = pd.read_csv(\"Machine Sequence.csv\")\n",
    "priority_due_date = pd.read_csv(\"Priority & Due Date.csv\")\n",
    "\n",
    "print(\"processing_time\\n\",processing_time.head(),\"\\n\")\n",
    "print(\"machine_seq\\n\",machine_sequence.head(),\"\\n\")\n",
    "print(\"Priority & Due Date\\n\",priority_due_date.head(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Initail Population (with defined encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the order is [1, 2, 1, 3, 3, ...]\n",
    "# meaning J1 first operation -> J2 first operation  -> J1 second operation......\n",
    "\n",
    "def initialize_population(pop_size, num_jobs):\n",
    "    # Create an array with numbers 1 to 10 repeated 10 times\n",
    "    base_array = np.tile(np.arange(1, 11), num_jobs) \n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        individual = np.random.permutation(base_array)\n",
    "        population.append(individual)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (fitness score, crowding distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness_score(individual):\n",
    "    \n",
    "    # Ji shows how many times of operation have been down\n",
    "    # Ji_end shows the time that last Ji ends\n",
    "    job_calculator = {}\n",
    "    for i in range(num_jobs):\n",
    "        job_calculator[f\"J{i+1}\"] = 0\n",
    "        job_calculator[f\"J{i+1}_end\"] = 0\n",
    "\n",
    "    # machine time shows the time that last job ends\n",
    "    machine_time = {f'M{i+1}': 0 for i in range(num_machines)}\n",
    "    \n",
    "    for job in individual:\n",
    "        \n",
    "        # shows the progess of each jobs\n",
    "        job_name = f\"J{job}\"\n",
    "        job_calculator[job_name]+=1\n",
    "        current_operation = job_calculator[job_name]\n",
    "        \n",
    "        job_operation = machine_sequence[machine_sequence[\"Job\"]==job_name]\n",
    "        # Find the column with number of times of operation\n",
    "        operation_name = job_operation.columns[job_operation[job_operation == current_operation].any()][0]\n",
    "        operation_number = int(operation_name.split(\"O\")[1])\n",
    "                \n",
    "        # check the time that operation takes\n",
    "        duration = processing_time[processing_time[\"Job\"]==job_name][f'O{operation_number}'].values[0]\n",
    "        \n",
    "        #  machine number = operation number\n",
    "        machine_name = f\"M{operation_number}\"\n",
    "        machine_time[machine_name] = max(machine_time[machine_name], job_calculator[f\"{job_name}_end\"])\n",
    "        machine_time[machine_name] += duration\n",
    "        job_calculator[f\"{job_name}_end\"] = machine_time[machine_name]\n",
    "        \n",
    "        # check code's correctness\n",
    "        # print(f\"job = {job_name}, times = {current_operation} ,operation = {operation_number}, time_spent = {duration}\")\n",
    "        \n",
    "    # calcualte makespan & twet\n",
    "    # print(f\"j {job_calculator.values()}\")\n",
    "    # print(f\"m {machine_time.values()}\")\n",
    "    \n",
    "    makespan = 0\n",
    "    twet = 0\n",
    "    for k,v in job_calculator.items():\n",
    "        if k.endswith(\"end\"):\n",
    "            due_date = priority_due_date[priority_due_date[\"Job\"] ==k.split(\"_\")[0]][\"Due date\"].values[0]\n",
    "            twet += abs(due_date - v)\n",
    "            # print(f\"d : {due_date} - end : {v}\")\n",
    "            makespan = max(makespan, v) \n",
    "            \n",
    "    return makespan, twet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-dominated sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input a three dimensional matrix with [[population, makespan, twet], ...]\n",
    "def dominates(individual1, individual2):\n",
    "    \"\"\"\n",
    "    Check if individual1 dominates individual2.\n",
    "    An individual dominates another if it is no worse in all objectives\n",
    "    and strictly better in at least one objective.\n",
    "    \"\"\"\n",
    "    and_condition = np.all(individual1 <= individual2)\n",
    "    or_condition = np.any(individual1 < individual2)\n",
    "    \n",
    "    # only\n",
    "    return and_condition and or_condition\n",
    "\n",
    "def non_dominated_sorting(population_matrix_with_target_value):\n",
    "    population_size = len(population_matrix_with_target_value)\n",
    "    # count how many pupolation dominated_count[i] is dominated\n",
    "    dominated_count = np.zeros(population_size)\n",
    "    dominates_list = [[] for _ in range(population_size)]\n",
    "    ranks = np.zeros(population_size)\n",
    "\n",
    "    # Determine the domination status\n",
    "    for i in range(population_size):\n",
    "        for j in range(population_size):\n",
    "            if i != j:\n",
    "                # compare i dominates j, or opposite\n",
    "                if dominates(np.array(population_matrix_with_target_value[i][1:]), np.array(population_matrix_with_target_value[j][1:])):\n",
    "                    dominates_list[i].append(j)\n",
    "                elif dominates(np.array(population_matrix_with_target_value[j][1:]), np.array(population_matrix_with_target_value[i][1:])):\n",
    "                    dominated_count[i] += 1\n",
    "\n",
    "        # If i is not dominated by any other solution\n",
    "        if dominated_count[i] == 0:\n",
    "            ranks[i] = 1\n",
    "          \n",
    "    \"\"\"\n",
    "    1. visit all the population rank = current_rank (initial = 1)\n",
    "    2. visit set member's and dominated number -1  \n",
    "    3. if dominated number == 1 , rank = i \n",
    "    4. visit all the population rank == 1 , current_rank ++ , start from step 1\n",
    "    \"\"\"\n",
    "    current_rank = 1\n",
    "    while np.any(ranks == current_rank):\n",
    "        for i in range(population_size):\n",
    "            if ranks[i] == current_rank:\n",
    "                for j in dominates_list[i]:\n",
    "                    dominated_count[j] -= 1\n",
    "                    if dominated_count[j] == 0:\n",
    "                        ranks[j] = current_rank + 1\n",
    "        current_rank += 1\n",
    "    \n",
    "    pd_population = pd.DataFrame(population_matrix_with_target_value,columns=[\"population\", \"makespan\", \"twet\"])\n",
    "    pd_population[\"rank\"] = ranks\n",
    "        \n",
    "    return pd_population.sort_values(by=\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =np.array([1588, 6791])\n",
    "b= np.array([1594, 5685])\n",
    "and_condition = np.all(a <= b)\n",
    "or_condition = np.any(a < b)\n",
    "\n",
    "and_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate crowding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_crowding_distance(array):\n",
    "    distance = np.zeros( len(array))\n",
    "    \n",
    "    # argsort first sort then give us the index of unsorted array\n",
    "    # e.g. np.argsort([3,1,2]) = [1 (the index of first small value in unsorted array),2,0]\n",
    "    sorted_indices = np.argsort(array)\n",
    "    sorted_array = array[sorted_indices]\n",
    "    \n",
    "    # the CD of chromosome who has smallest or biggest value at objective = infinity\n",
    "    distance[sorted_indices[0]] = np.inf\n",
    "    distance[sorted_indices[-1]] = np.inf\n",
    "    # calculate\n",
    "    regulation = abs(sorted_array[0] - sorted_array[-1]) if abs(sorted_array[0] - sorted_array[-1])!=0 else 1\n",
    "    for i in range(1, len(array) - 1):\n",
    "        distance[sorted_indices[i]] = (sorted_array[i+1] - sorted_array[i-1]) / regulation\n",
    "    # print(f' distance {distance}')\n",
    "    return distance\n",
    "\n",
    "def CD(ranked_population):\n",
    "    grouped = pd.DataFrame(ranked_population).groupby('rank')\n",
    "    result_df = pd.DataFrame()\n",
    "    for name, group in grouped:   \n",
    "        group[\"CD\"] = calculate_crowding_distance(group['makespan'].values) + calculate_crowding_distance(group['twet'].values)\n",
    "        \n",
    "        # get result_df by add another column \"CD\" to the ranked_population\n",
    "        result_df = pd.concat([result_df, group], ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tournament method\n",
    "def selection(ranked_populatoin_with_CD, pop_size ,number_of_competitors):\n",
    "    population = ranked_populatoin_with_CD[\"population\"]\n",
    "    rank = ranked_populatoin_with_CD[\"rank\"] \n",
    "    CD = ranked_populatoin_with_CD[\"CD\"]\n",
    "    makespan = ranked_populatoin_with_CD[\"makespan\"]\n",
    "    twet = ranked_populatoin_with_CD[\"twet\"]\n",
    "    selected = []\n",
    "    for _ in range(pop_size):\n",
    "        # note: I decide to user random sample instead of permutation to increase diversity\n",
    "        competitors = np.random.permutation(len(population))[:number_of_competitors]\n",
    "\n",
    "        # find the top rank's index of every chromosomes\n",
    "        final_competitors = []\n",
    "        v = min(rank[i] for i in competitors)\n",
    "        for i in competitors:\n",
    "            if rank[i] == v:\n",
    "                final_competitors.append(i)\n",
    "        \n",
    "        v = max(CD[i] for i in final_competitors)\n",
    "        for i in final_competitors:\n",
    "            if CD[i]==v:\n",
    "                selected.append([population[i], makespan[i], twet[i]])\n",
    "                break\n",
    "        \n",
    "    return pd.DataFrame(selected,columns=[\"population\", \"makespan\", \"twet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover & Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Davisâ€™ Order Crossover(for Job Shop Scheduling)\n",
    "def crossover(individual1, individual2):\n",
    "    length = len(individual1)\n",
    "    \n",
    "    # Initialize the offspring with None values\n",
    "    offspring1 = [None] * length\n",
    "    offspring2 = [None] * length\n",
    "    \n",
    "    # Choose two crossover points\n",
    "    cxpoint1, cxpoint2 = sorted(random.sample(range(length), 2))\n",
    "    \n",
    "    # Copy the sub-sequence from parent1 to offspring1 and parent2 to offspring2\n",
    "    offspring1[cxpoint1:cxpoint2] = individual1[cxpoint1:cxpoint2]\n",
    "    offspring2[cxpoint1:cxpoint2] = individual2[cxpoint1:cxpoint2]\n",
    "    \n",
    "    # Create a counter for each offspring\n",
    "    counter1 = Counter(offspring1[cxpoint1:cxpoint2])\n",
    "    counter2 = Counter(offspring2[cxpoint1:cxpoint2])\n",
    "    \n",
    "    def fill_offspring(parent, offspring, counter):\n",
    "        current_pos = cxpoint2\n",
    "        for gene in parent:\n",
    "            if counter[gene] < 10:\n",
    "                while offspring[current_pos] is not None:\n",
    "                    current_pos = (current_pos + 1) % length\n",
    "                offspring[current_pos] = gene\n",
    "                counter[gene] += 1\n",
    "    \n",
    "    # Fill the rest of the genes in the offspring\n",
    "    fill_offspring(individual2, offspring1, counter1)\n",
    "    fill_offspring(individual1, offspring2, counter2)\n",
    "    \n",
    "    return [offspring1, offspring2]\n",
    "\n",
    "# Change side if \n",
    "def mutate(individual):\n",
    "    i, j = random.sample(range(len(individual)), 2)\n",
    "    individual[i], individual[j] = individual[j], individual[i]\n",
    "\n",
    "# # Example usage\n",
    "# individual1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] * 10\n",
    "# individual2 = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] * 10\n",
    "\n",
    "# offspring1, offspring2 = crossover(individual1, individual2)\n",
    "# print(\"Offspring 1:\", offspring1)\n",
    "# print(\"Offspring 2:\", offspring2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elitsm Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elitism_strategy(population, number_of_survivors):\n",
    "    sorted_df = population.sort_values(by=['rank', 'CD'], ascending=[True, False])\n",
    "    survivors_df = sorted_df.head(number_of_survivors)\n",
    "    return survivors_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Gantt Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.plotly as py\n",
    "# import plotly.figure_factory as ff\n",
    "# import datetime\n",
    "\n",
    "# def plot_gantt(best_list):\n",
    "#     pt_tmp=pd.read_csv(\"Processing Time.csv\",index_col =[0])\n",
    "# ms_tmp=pd.read_csv(\"Machines Sequence.csv\",index_col =[0])\n",
    "# job_priority_duedate_tmp=pd.read_csv(\"Priority and Due Date.csv\",index_col =[0])\n",
    "\n",
    "# m_keys=[j+1 for j in range(num_machines)]\n",
    "# j_keys=[j for j in range(num_jobs)]\n",
    "# key_count={key:0 for key in j_keys}\n",
    "# j_count={key:0 for key in j_keys}\n",
    "# m_count={key:0 for key in m_keys}\n",
    "# j_record={}\n",
    "\n",
    "# pt=[list(map(int, processing_time.iloc[i])) for i in range(num_jobs)]\n",
    "# ms=[list(map(int,machine_sequence.iloc[i])) for i in range(num_machines)]\n",
    "\n",
    "# for i in best_list[0]:\n",
    "#     gen_t=int(pt[i][key_count[i]])\n",
    "#     gen_m=int(ms[i][key_count[i]])\n",
    "#     j_count[i]=j_count[i]+gen_t\n",
    "#     m_count[gen_m]=m_count[gen_m]+gen_t\n",
    "    \n",
    "#     if m_count[gen_m]<j_count[i]:\n",
    "#         m_count[gen_m]=j_count[i]\n",
    "#     elif m_count[gen_m]>j_count[i]:\n",
    "#         j_count[i]=m_count[gen_m]\n",
    "    \n",
    "#     start=j_count[i]-pt[i][key_count[i]]\n",
    "#     start_time=str(datetime.timedelta(seconds=start)) # convert seconds to hours, minutes and seconds\n",
    "#     end_time=str(datetime.timedelta(seconds=j_count[i]))  \n",
    "#     j_record[(i,gen_m)]=[start_time,end_time]\n",
    "    \n",
    "#     key_count[i]=key_count[i]+1\n",
    "        \n",
    "\n",
    "# df=[]\n",
    "# for m in m_keys:\n",
    "#     for j in j_keys:\n",
    "#         df.append(dict(Task='Machine %s'%(m), Start='2018-07-14 %s'%(str(j_record[(j,m)][0])), Finish='2018-07-14 %s'%(str(j_record[(j,m)][1])),Resource='Job %s'%(j+1)))\n",
    "    \n",
    "# fig = ff.create_gantt(df, index_col='Resource', show_colorbar=True, group_tasks=True, showgrid_x=True, title='Job shop Schedule')\n",
    "# py.iplot(fig, filename='GA_job_shop_scheduling1', world_readable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSGA-II Implementation\n",
    "iteration = 0\n",
    "unranked_population = []\n",
    "population_list = []\n",
    "line_graph_data = []\n",
    "selected_population = []\n",
    "best_of_all = pd.DataFrame(columns=[\"population\", \"makespan\", \"twet\"])\n",
    "while(iteration <= max_iteration_time):\n",
    "    \n",
    "    if len(population_list) == 0 :\n",
    "        population_list = initialize_population(pop_size,num_jobs)\n",
    "    else:\n",
    "        population_list = selected_population[\"population\"]\n",
    "  \n",
    "    for population in population_list:\n",
    "        makespan, twet = evaluate_fitness_score(population)\n",
    "        unranked_population.append([population,makespan,twet])\n",
    "\n",
    "    ranked_population = non_dominated_sorting(unranked_population)\n",
    "\n",
    "    ranked_populatoin_with_CD = CD(ranked_population)\n",
    "    selected_population = selection(ranked_populatoin_with_CD,pop_size ,int(pop_size/5))\n",
    "\n",
    "    # crossover & mutation (with Elitism Strategy)\n",
    "    size = len(selected_population)\n",
    "    for i in range(size):\n",
    "        if random.random() < crossover_rate:\n",
    "            random_pick_index = random.randrange(0, size)\n",
    "            offsprings =crossover(selected_population[\"population\"].iloc[i], selected_population[\"population\"].iloc[random_pick_index])\n",
    "            for o in offsprings:\n",
    "                mkspn, twet = evaluate_fitness_score(o)\n",
    "                new_row = pd.DataFrame({\n",
    "                    'population': [o],\n",
    "                    'makespan': mkspn,\n",
    "                    'twet': twet\n",
    "                })\n",
    "                selected_population = pd.concat([selected_population,new_row],ignore_index=True)\n",
    "            \n",
    "        if random.random() < mutation_rate: \n",
    "            mkspn, twet = evaluate_fitness_score(selected_population[\"population\"].iloc[i])\n",
    "            mutate(selected_population[\"population\"].iloc[i])\n",
    "            new_row = pd.DataFrame({\n",
    "                    'population': [selected_population['population'].iloc[i]],\n",
    "                    'makespan': mkspn,\n",
    "                    'twet': twet\n",
    "                })\n",
    "            selected_population = pd.concat([selected_population,new_row],ignore_index=True)\n",
    "    \n",
    "    print(f\"interation: {iteration}\")\n",
    "    iteration+=1\n",
    "    print(f\"current population size: {len(selected_population)}\")\n",
    "    # elitism strategy\n",
    "    selected_population_with_rank = non_dominated_sorting(selected_population.values)\n",
    "    selected_population_with_cd_and_rank = CD(selected_population_with_rank)\n",
    "    selected_population = elitism_strategy(pd.DataFrame(selected_population_with_cd_and_rank), num_elitism_survivors)\n",
    "    \n",
    "    # show the current best result of all\n",
    "    top_ranked_df = pd.DataFrame(selected_population.head(1))\n",
    "    if (best_of_all.shape[0] == 0) or (dominates(top_ranked_df[['makespan', 'twet']].values, best_of_all[['makespan', 'twet']].values)):\n",
    "        best_of_all = top_ranked_df\n",
    "    \n",
    "    line_graph_data.append([top_ranked_df[\"makespan\"].values[0],top_ranked_df[\"twet\"].values[0]])\n",
    "    print(f\"makespan: {top_ranked_df[\"makespan\"].values[0]}, twet: {top_ranked_df[\"twet\"].values[0]}\")\n",
    "    print(f\"BEST makespan: {best_of_all[\"makespan\"].values[0]},BEST twet: {best_of_all[\"twet\"].values[0]}\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('col1', 'col2')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\okumo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('col1', 'col2')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol3\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m]\n\u001b[0;32m      5\u001b[0m })\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\okumo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\okumo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: ('col1', 'col2')"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3],\n",
    "    'col2': [4, 5, 6],\n",
    "    'col3': [7, 8, 9]\n",
    "})\n",
    "df[\"col1\",\"col2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "makespan_data = [i[0] for i in line_graph_data]\n",
    "twet_data = [i[1] for i in line_graph_data]\n",
    "x_axis = range(len(line_graph_data))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_axis, makespan_data, label='Makespan')\n",
    "plt.plot(x_axis, twet_data, label='TWET')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Trend of Makespan and TWET')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
